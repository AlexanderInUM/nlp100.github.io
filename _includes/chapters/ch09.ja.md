## 第9章: RNN, CNN, アテンション

### 80. ID番号への変換

問題51で構築した学習データ中の単語にユニークなID番号を付与したい．学習データ中で最も頻出する単語に`1`，2番目に頻出する単語に`2`，……といった方法で，学習データ中で2回以上出現する単語にID番号を付与せよ．そして，与えられた単語列に対して，ID番号の列を返す関数を実装せよ．ただし，出現頻度が2回未満の単語のID番号はすべて`0`とせよ．

### 81. RNNによる予測

ID番号で表現された単語列$$\boldsymbol{x} = (x_1, x_2, \dots, x_T)$$がある．ただし，$$T$$は単語列の長さ，$$x_t \in \mathbb{R}^{V}$$は単語のID番号のone-hot表記である（$$V$$は単語の総数である）．再帰型ニューラルネットワーク（RNN: Recurrent Neural Network）を用い，単語列$$\boldsymbol{x}$$からカテゴリ$$y$$を予測するモデルとして，次式を実装せよ．

$$
\overrightarrow{h}_0 = 0, \\
\overrightarrow{h}_t = {\rm \overrightarrow{RNN}}(W^{(0)} x_t, \overrightarrow{h}_{t-1}), \\
y = {\rm softmax}(W^{\rm (1)} \overrightarrow{h}_T)
$$

ただし，$$W^{(0)} \in \mathbb{R}^{300 \times V}$$は単語埋め込み行列（単語のone-hot表記から単語ベクトルに変換する行列），$$\overrightarrow{h}_t \in \mathbb{R}^{50}$$は時刻$$t$$の隠れ状態ベクトル，$$W^{(1)} \in \mathbb{R}^{4 \times 50}$$は隠れ状態ベクトルからカテゴリを予測するための行列である．
なお，この問題ではモデルの学習を行わず，ランダムに初期化された重み行列で$$y$$を計算するだけでよい．

### 82. 確率的勾配降下法による学習

確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，問題81で構築したモデルを学習せよ．訓練データ上の損失と正解率，評価データ上の損失と正解率を表示しながらモデルを学習し，適当な基準（例えば10エポックなど）で終了させよ．

### 83. ミニバッチ化・GPU上での学習

問題82のコードを改変し，$$B$$事例ごとに損失・勾配を計算して学習を行えるようにせよ（$$B$$の値は適当に選べ）．また，GPU上で学習を実行せよ．

### 84. 単語ベクトルの導入

事前学習済みの単語ベクトル（例えば，Google Newsデータセット（約1,000億単語）での[学習済み単語ベクトル](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing)）で単語埋め込み行列$$W_0$$を初期化し，学習せよ．

### 85. 双方向RNN・多層化

順方向と逆方向のRNNの両方を用いて入力テキストをエンコードし，モデルを学習せよ．

$$
\overleftarrow{h}_{T+1} = 0, \\
\overleftarrow{h}_t = {\rm \overleftarrow{RNN}}(W^{(0)} x_t, \overleftarrow{h}_{t+1}), \\
y = {\rm softmax}(W^{(1)} [\overrightarrow{h}_T; \overleftarrow{h}_1])
$$

ただし，$$\overleftarrow{h}_t \in \mathbb{R}^{50}$$は時刻$$t$$の隠れ状態ベクトル（左向き），$$W^{(1)} \in \mathbb{R}^{4 \times 100}$$は隠れ状態ベクトルからカテゴリを予測するための行列である．

また，RNNを多層化せよ．

### 86. 畳み込みニューラルネットワーク (CNN)

ID番号で表現された単語列$$\boldsymbol{x} = (x_1, x_2, \dots, x_T)$$がある．ただし，$$T$$は単語列の長さ，$$x_t \in \mathbb{R}^{V}$$は単語のID番号のone-hot表記である（$$V$$は単語の総数である）．畳み込みニューラルネットワーク（CNN: Convolutional Neural Network）を用い，単語列$$\boldsymbol{x}$$からカテゴリ$$y$$を予測するモデルを実装せよ．

ただし，

+ 単語埋め込みの次元数: 300
+ 畳み込みのフィルターのサイズ: 3 (トークン)
+ 畳み込みのストライド: 1 (トークン)
+ 畳み込みのパディング: あり
+ 畳み込み演算後の各時刻のベクトルの次元数: 50
+ 畳み込み演算後に最大値プーリング（max pooling）を適用し，入力文を50次元の隠れベクトルで表現

なお，この問題ではモデルの学習を行わず，ランダムに初期化された重み行列で$$y$$を計算するだけでよい．

### 87. 確率的勾配降下法によるCNNの学習

### 88. パラメータチューニング

### 89. BERT

[BERT](https://github.com/google-research/bert)を使い，ニュース記事見出しのカテゴリ分類器を構築せよ．
